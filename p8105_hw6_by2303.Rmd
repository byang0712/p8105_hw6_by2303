---
title: "Homework 6"
author: "Bin Yang"
date: "11/24/2020"
output: github_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(modelr)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

### Problem 1

```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```


Start with one city.

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")
glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```


Try this across cities.

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI")) 
```

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```



### Problem 2
  
* Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

```{r}
baby_df = read_csv("./data/birthweight.csv")

baby_lm = baby_df %>% 
  mutate(
    babysex = as.factor(babysex), 
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  )

sapply(baby_lm, function(x) sum(is.na(x))) %>% 
  knitr::kable(caption = "table for missing values", 
               col.names = c("missing value count"))
```

I converted babysex, frace, malform and mrace to factor.  There's no missing values in the dataset.  

* Propose a regression model for birthweight.  

I first created correlation plot for all continuous variables:

```{r}
cor_df = 
  baby_df %>% 
  select(-babysex, -frace, -malform, -mrace) %>% 
  select(bwt, everything())

mcor = round(cor(cor_df), 2)

upper<- mcor

upper[upper.tri(mcor)]<- ""

upper<- as.data.frame(upper)

upper %>% 
  arrange(desc(bwt)) %>% 
  knitr::kable(caption = "correlation matrxi for continuous variables")
```

I will choose the top 5 variables that have the largest correlation with birth weight, include all categorical variables as well as their interaction terms. 

```{r}
lm_proposed = lm(bwt ~ bhead + blength + gaweeks + delwt + wtgain + 
                   babysex + frace + malform + mrace, data = baby_lm)
```

Then I will use stepwise selection to find the best model:  

```{r}
stats::step(lm_proposed, direction = 'both')
```
  
And my final proposed model is:  

```{r}
lm_final = lm(formula = bwt ~ bhead + blength + gaweeks + delwt + wtgain + 
    babysex + mrace, data = baby_lm) 

summary(lm_final)
```

* Show a plot of model residuals against fitted values
```{r residual plot}
baby_lm %>% 
add_residuals(lm_final) %>% 
add_predictions(lm_final) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_line(y = 0, color = "red") + 
  labs(
    title = "residual vs fitted value plot",
    x = "fitted value(gram)",
    y = "residuals"
  )
```
  
* Compare your model to two others:  

```{r cv}
cv_df = crossv_mc(baby_df, 100)

cv_df = 
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    lm_final = map(train, ~lm(bwt ~ bhead + blength + gaweeks + delwt + wtgain + 
    babysex + mrace, data = .x)),
    lm_comp_1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    lm_comp_2 = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))
    ) %>% 
  mutate(
    rmse_final = map2_dbl(lm_final, test, ~rmse(model = .x, data = .y)),
    rmse_comp_1 = map2_dbl(lm_comp_1, test, ~rmse(model = .x, data = .y)),
    rmse_comp_2 = map2_dbl(lm_comp_2, test, ~rmse(model = .x, data = .y))
  )


cv_df %>% 
  select(starts_with("rmse")) %>% 
pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() + 
  labs(
    title = "prediction error: model comparison"
  )
```

We can see that the proposed final model has the lowest RMSE and is therefore the best performing model.  

### Problem 3  
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

* Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities.  
```{r, warning=FALSE}
set.seed(133)

boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, sample_frac(weather_df, replace = TRUE)))
```

```{r}
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x)),
    model_result = map(models, broom::glance),
    model_estimate = map(models, broom::tidy)) %>% 
  select(-strap_sample, -models) %>% 
  unnest() %>%
  select(strap_number, r.squared, term, estimate) %>%
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) %>%
  janitor::clean_names() %>%
  mutate(log_est = log(intercept * tmin))
```

* Plot the distribution of your estimates, and describe these in words.   

```{r}
bootstrap_results %>% 
  ggplot(aes(x = r_squared)) +
  geom_density() +
  xlab("Estimated r squared")
```
As observed from the density plot, the $\hat{r}^2$ has a bell-shape and is approximately normal with a mean value around 0.91. 


```{r}
bootstrap_results %>% 
  ggplot(aes(x = log_est)) +
  geom_density() +
  xlab("Log(Beta_0 x Beta_1)")
```
As observed from the density plot, the $log(\hat{\beta}_0*\hat{\beta}_1)$ is also approximately normal with a mean at around 2.10.   

*  identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval.  



